{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d0b8f8-9f94-4952-ad71-d2d8fdff8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mistralai --user\n",
    "# !pip install instructor  --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18a19b4d-fd59-4ddb-b74a-db0a6b7308e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY=\"\"\n",
    "mistral_api_key = MISTRAL_API_KEY#os.getenv('MISTRAL_API_KEY', 'your-mistral-api-key-here')\n",
    "fuelix_api_key = ''#os.getenv('FUELIX_API_KEY')  # Optional\n",
    "\n",
    "from mistralai import Mistral\n",
    "from mistralai import TextChunk\n",
    "import os\n",
    "from instructor import from_mistral, Mode\n",
    "from datetime import datetime,date\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90fb6d1d-a9ea-42f8-bcc3-dbe83154882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Encode the image to base64.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {image_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:  # Added general exception handling\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"cruise1.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7949d83-c8fb-4637-aa13-d34e45aa676e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMG_2877.jpeg',\n",
       " '5cIKcjGmaD-photo.png',\n",
       " 'sales-resume-example.png',\n",
       " 'images.jpeg',\n",
       " '.ipynb_checkpoints',\n",
       " 'front-end-developer-resume-examples.webp',\n",
       " 'image.png',\n",
       " 'data-engineer-resume-example.png',\n",
       " 'SalesEntryLevel.webp',\n",
       " 'aHR0cHM6Ly9jZG4uZW5oYW5jdi5jb20vcHJlZGVmaW5lZC1leGFtcGxlcy81dnZKWmJwNEZyRHNsRUxqOEtPMUxnQmNsMEs0RHpvc2tqVDVLUU1JL2ltYWdlLnBuZw~~.png',\n",
       " 'construction-project-manager-resume-example.png',\n",
       " 'Data-Engineer-reume-730x1024.webp',\n",
       " 'project-manager-resume.webp',\n",
       " 'Front-End-Web-Developer-Resume-Example.png',\n",
       " 'aHR0cHM6Ly9jZG4uZW5oYW5jdi5jb20vcHJlZGVmaW5lZC1leGFtcGxlcy92SjJzSndsSlVxYlRpMkJyTmJ4dzBXdnNNVFhWelduUGlDQTZ3STNIL2ltYWdlLnBuZw~~.png',\n",
       " 'aHR0cHM6Ly9jZG4uZW5oYW5jdi5jb20vcHJlZGVmaW5lZC1leGFtcGxlcy96VDNRQTAwVFg3SkRJelZlY1NvRXlDazlQWERHYklGd2h3WlpNc2VBL2ltYWdlLnBuZw~~.png',\n",
       " 'Construction-Project-Manager-Resume-Example (1).png',\n",
       " 'azure-data-engineer.png']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in os.listdir('resumes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a452bfc-f181-4b0f-997d-81d01987203c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ocr_image(base64_image):\n",
    "    client = Mistral(api_key=MISTRAL_API_KEY)\n",
    "\n",
    "    ocr_response = client.ocr.process(\n",
    "        model=\"mistral-ocr-latest\",\n",
    "        document={\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{base64_image}\" \n",
    "        },\n",
    "        include_image_base64=True\n",
    "    )\n",
    "\n",
    "    # print(ocr_response)\n",
    "    return ocr_response.pages[0].markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7788eec5-001b-493f-b659-13d0e07d439a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid image files: ['IMG_2877.jpeg', '5cIKcjGmaD-photo.png', 'sales-resume-example.png', 'images.jpeg', 'front-end-developer-resume-examples.webp', 'image.png', 'data-engineer-resume-example.png', 'SalesEntryLevel.webp', 'aHR0cHM6Ly9jZG4uZW5oYW5jdi5jb20vcHJlZGVmaW5lZC1leGFtcGxlcy81dnZKWmJwNEZyRHNsRUxqOEtPMUxnQmNsMEs0RHpvc2tqVDVLUU1JL2ltYWdlLnBuZw~~.png', 'construction-project-manager-resume-example.png', 'Data-Engineer-reume-730x1024.webp', 'project-manager-resume.webp', 'Front-End-Web-Developer-Resume-Example.png', 'aHR0cHM6Ly9jZG4uZW5oYW5jdi5jb20vcHJlZGVmaW5lZC1leGFtcGxlcy92SjJzSndsSlVxYlRpMkJyTmJ4dzBXdnNNVFhWelduUGlDQTZ3STNIL2ltYWdlLnBuZw~~.png', 'aHR0cHM6Ly9jZG4uZW5oYW5jdi5jb20vcHJlZGVmaW5lZC1leGFtcGxlcy96VDNRQTAwVFg3SkRJelZlY1NvRXlDazlQWERHYklGd2h3WlpNc2VBL2ltYWdlLnBuZw~~.png', 'Construction-Project-Manager-Resume-Example (1).png', 'azure-data-engineer.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# allowed image extensions\n",
    "valid_exts = {\".jpg\", \".jpeg\", \".png\", \".webp\", \".gif\", \".bmp\", \".tiff\", \".heif\", \".avif\", \".mpo\"}\n",
    "\n",
    "# filter files that are actual images\n",
    "image_files = [\n",
    "    f for f in os.listdir(\"resumes\")\n",
    "    if os.path.splitext(f)[1].lower() in valid_exts\n",
    "]\n",
    "\n",
    "print(\"Valid image files:\", image_files)\n",
    "\n",
    "# now run OCR only on valid images\n",
    "image_ocr_markdowna = [ocr_image(encode_image(os.path.join(\"resumes\", f))) for f in image_files]\n",
    "\n",
    "#image_ocr_markdowna = [ocr_image(encode_image('resumes/'+i)) for i in os.listdir('resumes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab784b3-d8a6-4770-b855-c2de90dde523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a03bac5-1e95-4ccc-a695-bc7bf442d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ocr_markdown = image_ocr_markdowna[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "697d0833-44d5-4f04-bb77-bf9712cb046c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Education \\n\\n- Birla Institute of Technology and Science, Pilani\\n\\nHyderabad, India\\nBE Electronics and Instrumentation and MSc Math (Dual Degree) GPA: 6.98/10\\nOct. 2021 - June. 2026\\n\\n## Relevant Coursework\\n\\n- Computer Architecture, Digital Design, Analog and digital VLSI Design, Microelectronic Circuits, Electronic devices, FPGA Based System Design, Computer Programming, Microprocessors and Interfacing.\\n\\n\\n## Professional Interest\\n\\nInterested in VLSI domain, particularly in Design Verification, with a focus on gaining hands on experience using industry standard EDA tools and frameworks, understanding semiconductor technologies, and contributing to projects while learning from mentors.\\n\\n## Projects\\n\\n## - Five-Stage Pipelined RISC Processor\\n\\n- Verilog, Digital Design, Computer Architecture\\n\\nFeb 2025 - Apr 2025\\n0 : Designed a 32-bit processor based on the MIPS ISA with a 5-stage pipeline: IF, ID, EX, MEM, WB\\n0 : Developed modules for pipelined registers, ALU, PC, register file, memory, and other essential logic blocks.\\n0 : Implemented forwarding and hazard detection units to resolve data and control hazards.\\n\\n## - SHA-256 based Sensor Authenticator on FPGA\\n\\n- Verilog, FPGA Based System Design\\n\\nOct 2024 - Dec 2024\\n0 : Implemented SHA-256 algorithm on ZedBoard to enable fast and secure cryptographic hashing.\\n0 : Interfaced a keypad and a stepper motor with the FPGA for user input and real-time motor control.\\n0 : Authenticated motor controls using a 6-digit reconfigurable passcode for system security and flexibility.\\n\\n## - FPGA Image Processing System\\n\\n- Verilog, Digital Design, $C$\\n\\nMay 2023 - Jul 2023\\n0 : Designed an image processing system on ZedBoard using Vivado-Vitis, utilizing the Zynq architecture.\\n0 : Implemented line buffers and MAC units for kernel operations, with DMA enabling DDR-to-PL data transfer.\\n0 : Handled PS-PL interrupts and added Buffers for synchronized data processing.\\n0 : Interfaced the system with HDMI and VGA for real-time video output.\\n\\n## Technical Skills\\n\\n- Languages: Python, Verilog, C++, C, MATLAB.\\n- Skills/Tools: Computer Architecture, SPICE, Magic VLSI, Vivado-Vitis, FPGA Based Design.\\n\\n\\n## Co-Curricular Activities\\n\\n- National Service Scheme (NSS): Part of the volunteer group of NSS, Bits Pilani Hyderabad Campus.\\n- FPGA Hackathon: Participated in a inter-campus FPGA system design Hackathon Interfacing ESP32 PMOD to Zedboard using Vivado-Vitis tools.\\n\\n\\n## Additional Information\\n\\nActively pursuing Design Verification training through a Udemy course focused on SystemVerilog, UVM, UVM-RAL, functional coverage, and assertions to strengthen verification concepts along with Communication protocols.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ocr_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e594d79-f2ed-4794-829b-b9258fe52206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instructor import from_openai, Mode\n",
    "from openai import OpenAI\n",
    "from datetime import datetime, date\n",
    "from typing import Optional, List, Type, Any, get_origin, get_args\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "\n",
    "class FieldDefinition(BaseModel):\n",
    "    name: str\n",
    "    field_type: str  # \"str\", \"Optional[str]\", \"datetime\", \"Optional[datetime]\", etc.\n",
    "    description: str\n",
    "    alias: Optional[str] = None\n",
    "\n",
    "class DynamicSchema(BaseModel):\n",
    "    model_name: str\n",
    "    context_purpose: str\n",
    "    fields: List[FieldDefinition]\n",
    "    reasoning: str\n",
    "\n",
    "class DocumentExtractionUtility:\n",
    "    def __init__(self, fuelix_api_key: str, schema_model: str = \"gpt-4o-mini\"):\n",
    "        self.fuel_ix_client = from_openai(\n",
    "            OpenAI(\n",
    "                base_url='https://api-beta.fuelix.ai/', \n",
    "                api_key=fuelix_api_key\n",
    "            ),\n",
    "            mode=Mode.JSON\n",
    "        )\n",
    "        self.schema_model = schema_model\n",
    "\n",
    "    def _parse_field_type(self, type_str: str) -> tuple[Type, Any]:\n",
    "        \"\"\"Convert string type to actual Python type and ensure it's optional\"\"\"\n",
    "        type_str = type_str.strip()\n",
    "\n",
    "        # Handle Optional types\n",
    "        if type_str.startswith(\"Optional[\") and type_str.endswith(\"]\"):\n",
    "            inner_type = type_str[9:-1]  # Remove \"Optional[\" and \"]\"\n",
    "            base_type, _ = self._parse_field_type(inner_type)\n",
    "            return Optional[base_type], None\n",
    "\n",
    "        # Handle basic types\n",
    "        type_mapping = {\n",
    "            \"str\": str,\n",
    "            \"int\": int,\n",
    "            \"float\": float,\n",
    "            \"bool\": bool,\n",
    "            \"datetime\": datetime,\n",
    "            \"date\": date,\n",
    "        }\n",
    "\n",
    "        if type_str in type_mapping:\n",
    "            # Always wrap in Optional to ensure all fields are optional\n",
    "            return Optional[type_mapping[type_str]], None\n",
    "        else:\n",
    "            # Default to Optional[str] if unknown type\n",
    "            return Optional[str], None\n",
    "\n",
    "    def create_model_from_schema(self, schema: DynamicSchema) -> Type[BaseModel]:\n",
    "        \"\"\"Create a Pydantic model from schema definition with all fields optional\"\"\"\n",
    "        fields = {}\n",
    "\n",
    "        for field_def in schema.fields:\n",
    "            field_type, default_value = self._parse_field_type(field_def.field_type)\n",
    "\n",
    "            # Handle aliases\n",
    "            field_kwargs = {}\n",
    "            if field_def.alias:\n",
    "                field_kwargs['alias'] = field_def.alias\n",
    "\n",
    "            # All fields are now optional with None as default\n",
    "            fields[field_def.name] = (field_type, Field(None, description=field_def.description, **field_kwargs))\n",
    "\n",
    "        # Create the dynamic model\n",
    "        DynamicModel = create_model(schema.model_name, **fields)\n",
    "        return DynamicModel\n",
    "\n",
    "    def generate_schema(self, context: str, ocr_sample: str) -> DynamicSchema:\n",
    "        \"\"\"Generate extraction schema based on context and document sample\"\"\"\n",
    "\n",
    "        schema_prompt = f\"\"\"\n",
    "Context: {context}\n",
    "\n",
    "Sample Document OCR Output:\n",
    "{ocr_sample}\n",
    "\n",
    "Based on this context and document sample, define a comprehensive data extraction schema.\n",
    "\n",
    "Guidelines:\n",
    "- Use snake_case for field names\n",
    "- Available types: str, int, float, bool, datetime, date, Optional[str], Optional[int], Optional[datetime], etc.\n",
    "- ALL fields should be Optional[] - this is mandatory for flexible extraction\n",
    "- Use aliases for Python keywords (e.g., \"from\" should have alias)\n",
    "- Consider what fields would be most valuable for the given context\n",
    "- Include clear descriptions for each field\n",
    "- Avoid making big sentences as part of the output schema. We want objective, normalized (in database terms) details like list of names, address etc\n",
    "- Remember: Every single field must be Optional to handle cases where information might be missing\n",
    "\n",
    "Generate a schema with model name, context purpose, field definitions, and reasoning.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.fuel_ix_client.chat.completions.create(\n",
    "                model=self.schema_model,\n",
    "                response_model=DynamicSchema,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a schema generation expert. Generate clean, practical and objective schemas for document extraction. ALL FIELDS MUST BE OPTIONAL. Examples: Optional[str] for name, Optional[int] for age, Optional[str] for phone_number, Optional[str] for pnr\"},\n",
    "                    {\"role\": \"user\", \"content\": schema_prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_retries=5\n",
    "            )\n",
    "            \n",
    "            # Post-process to ensure all fields are optional\n",
    "            for field in response.fields:\n",
    "                if not field.field_type.startswith(\"Optional[\"):\n",
    "                    # Wrap non-optional types in Optional\n",
    "                    field.field_type = f\"Optional[{field.field_type}]\"\n",
    "            \n",
    "            return response\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Schema generation failed: {str(e)}\")\n",
    "\n",
    "    def extract_data(self, DynamicModel, ocr_text: str) -> BaseModel:\n",
    "        \"\"\"Extract data using the generated schema\"\"\"\n",
    "\n",
    "        extraction_prompt = f\"\"\"\n",
    "Extract the following information from this document:\n",
    "\n",
    "Document OCR Text:\n",
    "{ocr_text}\n",
    "\n",
    "Extract all available fields. Use None/null for missing information.\n",
    "All fields are optional, so don't worry if some information is not present in the document.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            extraction_response = self.fuel_ix_client.chat.completions.create(\n",
    "                model=self.schema_model,\n",
    "                response_model=DynamicModel,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a data extraction expert. Extract information accurately from documents. Set fields to None if information is not available.\"},\n",
    "                    {\"role\": \"user\", \"content\": extraction_prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_retries=5\n",
    "            )\n",
    "            return extraction_response\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Data extraction failed: {str(e)}\")\n",
    "\n",
    "    def process_document(self, context: str, ocr_text: str, schema=None) -> tuple[DynamicSchema, BaseModel]:\n",
    "        \"\"\"Complete pipeline: generate schema and extract data\"\"\"\n",
    "        if not schema:\n",
    "            print(\":arrows_counterclockwise: Generating extraction schema...\")\n",
    "            schema = self.generate_schema(context, ocr_text)\n",
    "\n",
    "        print(f\":white_check_mark: Generated schema: {schema.model_name}\")\n",
    "        print(f\":clipboard: Fields: {len(schema.fields)} (all optional)\")\n",
    "        print(f\":thought_balloon: Reasoning: {schema.reasoning}\")\n",
    "        print()\n",
    "\n",
    "        print(\":arrows_counterclockwise: Extracting data...\")\n",
    "        DynamicModel = self.create_model_from_schema(schema)\n",
    "\n",
    "        extracted_data = self.extract_data(DynamicModel, ocr_text)\n",
    "\n",
    "        print(\":white_check_mark: Data extraction complete!\")\n",
    "\n",
    "        return schema, extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bf22d2e-4ac2-4e81-b788-99673496a976",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":arrows_counterclockwise: Generating extraction schema...\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 13 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential details from resumes, allowing for structured data extraction despite potential OCR inaccuracies. Each field is designed to be optional to accommodate varying levels of completeness in resume submissions.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured information from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential details from resumes, allowing for structured data extraction despite potential OCR inaccuracies. Each field is designed to be optional to accommodate varying levels of completeness in resume submissions.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or area of expertise\n",
      "  • experience_years: Optional[integer]\n",
      "    └─ Total years of professional experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • gpa: Optional[float]\n",
      "    └─ Grade Point Average of the candidate\n",
      "  • relevant_coursework: Optional[array]\n",
      "    └─ List of relevant coursework completed\n",
      "  • projects: Optional[array]\n",
      "    └─ List of projects undertaken by the candidate\n",
      "  • technical_skills: Optional[array]\n",
      "    └─ List of technical skills and tools known\n",
      "  • co_curricular_activities: Optional[array]\n",
      "    └─ List of co-curricular activities participated in\n",
      "  • additional_information: Optional[string]\n",
      "    └─ Any additional information relevant to the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": null,\n",
      "  \"email\": null,\n",
      "  \"phone_number\": null,\n",
      "  \"location\": \"Hyderabad, India\",\n",
      "  \"primary_skill\": \"VLSI Design Verification\",\n",
      "  \"experience_years\": null,\n",
      "  \"education\": \"BE Electronics and Instrumentation and MSc Math (Dual Degree)\",\n",
      "  \"gpa\": 6.98,\n",
      "  \"relevant_coursework\": \"Computer Architecture, Digital Design, Analog and digital VLSI Design, Microelectronic Circuits, Electronic devices, FPGA Based System Design, Computer Programming, Microprocessors and Interfacing.\",\n",
      "  \"projects\": \"Five-Stage Pipelined RISC Processor, SHA-256 based Sensor Authenticator on FPGA, FPGA Image Processing System\",\n",
      "  \"technical_skills\": \"Languages: Python, Verilog, C++, C, MATLAB. Skills/Tools: Computer Architecture, SPICE, Magic VLSI, Vivado-Vitis, FPGA Based Design.\",\n",
      "  \"co_curricular_activities\": \"National Service Scheme (NSS): Part of the volunteer group of NSS, Bits Pilani Hyderabad Campus. FPGA Hackathon: Participated in a inter-campus FPGA system design Hackathon Interfacing ESP32 PMOD to Zedboard using Vivado-Vitis tools.\",\n",
      "  \"additional_information\": \"Actively pursuing Design Verification training through a Udemy course focused on SystemVerilog, UVM, UVM-RAL, functional coverage, and assertions to strengthen verification concepts along with Communication protocols.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Usage Example\n",
    "# Sample OCR text (flight booking confirmation)\n",
    "sample_flight_ocr =image_ocr_markdown\n",
    "\n",
    "#     \"\"\"\n",
    "#     BOOKING CONFIRMATION\n",
    "\n",
    "#     Passenger: John Smith\n",
    "#     Email: john.smith@email.com\n",
    "#     PNR: ABC123\n",
    "#     Booking Reference: XYZ789\n",
    "\n",
    "#     Flight Details:\n",
    "#     Flight: AI 101\n",
    "#     From: Delhi (DEL)\n",
    "#     To: Mumbai (BOM)\n",
    "#     Date: 15-Dec-2024\n",
    "#     Departure: 14:30\n",
    "#     Arrival: 16:45\n",
    "#     Terminal: T3\n",
    "\n",
    "#     Status: Confirmed\n",
    "#     Booking Date: 01-Dec-2024 10:30:00 UTC\n",
    "#     \"\"\"\n",
    "\n",
    "# Initialize the utility (you'll need to define these variables)\n",
    "FUELIX_API_KEY = fuelix_api_key#\"your-fuelix-api-key-here\"\n",
    "SCHEMA_MODEL = \"gpt-4o-mini\"  # or whatever model you want to use\n",
    "\n",
    "extractor = DocumentExtractionUtility(FUELIX_API_KEY, SCHEMA_MODEL)\n",
    "\n",
    "# Define context\n",
    "context = \"Sharing noisey OCR output of Resumes. Come up with schemas that can help categorize and identify the data like primary skill,location, experience in years(integer),name,email etc\"\n",
    "\n",
    "try:\n",
    "    # Process the document\n",
    "    schema, extracted_data = extractor.process_document(context, sample_flight_ocr)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"GENERATED SCHEMA:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Model Name: {schema.model_name}\")\n",
    "    print(f\"Context: {schema.context_purpose}\")\n",
    "    print(f\"Reasoning: {schema.reasoning}\")\n",
    "    print(\"\\nFields:\")\n",
    "    for field in schema.fields:\n",
    "        alias_info = f\" (alias: {field.alias})\" if field.alias else \"\"\n",
    "        print(f\"  • {field.name}: {field.field_type}{alias_info}\")\n",
    "        print(f\"    └─ {field.description}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"EXTRACTED DATA:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(extracted_data.model_dump_json(indent=2))\n",
    "except Exception as e:\n",
    "    print(f\":x: Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5356aae-f091-400b-b6dc-ec63150cca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0488b-9049-4d48-b96d-85e60297211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export schema to JSON file (2 lines)\n",
    "import json\n",
    "with open('schema.json', 'w') as f: json.dump(schema.model_dump(), f, indent=2)\n",
    "\n",
    "# Import schema from JSON file (2 lines)  \n",
    "with open('schema.json', 'r') as f: schema_dict = json.load(f)\n",
    "schema = DynamicSchema(**schema_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3d72b16-5b66-45df-abaa-74ff95f7a6fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSchema(model_name='ResumeDataExtraction', context_purpose='Extract structured data from noisy OCR output of resumes.', fields=[FieldDefinition(name='name', field_type='Optional[string]', description='Full name of the candidate', alias=None), FieldDefinition(name='email', field_type='Optional[string]', description='Email address of the candidate', alias=None), FieldDefinition(name='phone_number', field_type='Optional[string]', description='Contact phone number of the candidate', alias=None), FieldDefinition(name='location', field_type='Optional[string]', description='Current location of the candidate', alias=None), FieldDefinition(name='primary_skill', field_type='Optional[string]', description='Main skill or job title of the candidate', alias=None), FieldDefinition(name='experience_years', field_type='Optional[int]', description='Total years of relevant work experience', alias=None), FieldDefinition(name='education', field_type='Optional[string]', description='Educational background of the candidate', alias=None), FieldDefinition(name='certifications', field_type='Optional[string]', description='List of certifications obtained by the candidate', alias=None), FieldDefinition(name='skills', field_type='Optional[array]', description='List of skills and techniques possessed by the candidate', alias=None), FieldDefinition(name='languages', field_type='Optional[array]', description='Languages spoken by the candidate', alias=None), FieldDefinition(name='previous_experience', field_type='Optional[array]', description='List of previous job titles and companies', alias=None), FieldDefinition(name='projects', field_type='Optional[array]', description='List of significant projects worked on by the candidate', alias=None)], reasoning='This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4ce92-9c73-4fab-af0d-bb98aa1154e7",
   "metadata": {},
   "source": [
    "# Using The Schema Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b5dd12a-d587-47b9-bbb1-33e74a0acd71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"MARVIN TELLO\",\n",
      "  \"email\": \"mtello@email.com\",\n",
      "  \"phone_number\": \"(123) 456-7890\",\n",
      "  \"location\": \"San Antonio, TX\",\n",
      "  \"primary_skill\": \"Lead Sales Specialist\",\n",
      "  \"experience_years\": 5,\n",
      "  \"education\": \"Bachelor of Arts in Business Management from Texas A&M University, Central Texas\",\n",
      "  \"certifications\": null,\n",
      "  \"skills\": \"Negotiation, CRM (Salesforce), Problem-solving, Lead Generation (LinkedIn, email), Reporting, Results-oriented, Microsoft Office (Word, Excel, PowerPoint)\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Sales Specialist at Humana, Sales Representative at TQL, Sales Assistant at Family Dollar\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"Chris Wilkes\",\n",
      "  \"email\": \"chris_wilkes99@gmail.com\",\n",
      "  \"phone_number\": \"407-790-3421\",\n",
      "  \"location\": \"Orlando, FL 32789, United States\",\n",
      "  \"primary_skill\": \"Front End Developer\",\n",
      "  \"experience_years\": 8,\n",
      "  \"education\": \"Bachelor of Science in Computer Science, University of Central Florida, Orlando\",\n",
      "  \"certifications\": null,\n",
      "  \"skills\": null,\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Senior Front End Developer, IXF, Orlando; Front End Developer, Sasco Group, Orlando\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"ALAN SUSA\",\n",
      "  \"email\": \"alansusa@email.com\",\n",
      "  \"phone_number\": \"(123) 456-7890\",\n",
      "  \"location\": \"New York, NY\",\n",
      "  \"primary_skill\": \"Data Engineer\",\n",
      "  \"experience_years\": 9,\n",
      "  \"education\": \"B.A. in Computer Science from University of Pittsburgh (September 2010 - April 2014)\",\n",
      "  \"certifications\": null,\n",
      "  \"skills\": \"Python, ETLs, SQL (Postgres, Redshift, MySQL), NoSQL (MongoDB), Spark, Kafka, Airflow, AWS (Athena, Lambda, S3)\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Data Engineer at Consumer Reports, Data Engineer at Guardian Life Insurance Company, Data Engineer Intern at Federal Reserve Board of Governors\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"Meera Patel\",\n",
      "  \"email\": \"meerapatel@example.com\",\n",
      "  \"phone_number\": \"(720) 555-5678\",\n",
      "  \"location\": \"San Diego, CA 92102\",\n",
      "  \"primary_skill\": \"Inside Sales\",\n",
      "  \"experience_years\": 2,\n",
      "  \"education\": \"Bachelor of Science in Marketing from University of San Diego at San Diego, CA\",\n",
      "  \"certifications\": null,\n",
      "  \"skills\": \"Cold calling, Consultative selling, Inside sales, Lead qualification, Salesforce CRM\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Inside Sales Representative at Decker Software, San Diego, CA; Inside Sales Representative at State Farm Insurance, San Diego, CA\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"James Jones\",\n",
      "  \"email\": \"help@enhancv.com\",\n",
      "  \"phone_number\": null,\n",
      "  \"location\": \"San Antonio, Texas\",\n",
      "  \"primary_skill\": \"Senior Backend Software Engineer\",\n",
      "  \"experience_years\": 5,\n",
      "  \"education\": \"Master's degree in Computer Science\",\n",
      "  \"certifications\": \"Advanced Database Systems, Machine Learning with Python\",\n",
      "  \"skills\": \"Python, C++, AWS Services, SQL, MySQL, PostgreSQL, NoSQL databases, Atlassian JIRA, Confluence, Terraform, Git, CI/CD, Agile Methodologies\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Senior Backend Software Engineer at MedTech Solutions (2019 - 2022, London, United Kingdom); Backend Software Engineer at HealthTech Innovations (2017 - 2019, San Francisco, CA)\",\n",
      "  \"projects\": \"Open Health Data API, Medical Data Visualization Tool\"\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"CHASTITY YABUT\",\n",
      "  \"email\": \"Chas@email.com\",\n",
      "  \"phone_number\": \"(123) 456-7890\",\n",
      "  \"location\": \"Miami, FL\",\n",
      "  \"primary_skill\": \"CONSTRUCTION PROJECT MANAGER\",\n",
      "  \"experience_years\": 11,\n",
      "  \"education\": \"Bachelor of Science Business Administration, University of Florida, 2004 - 2008, Gainesville, FL\",\n",
      "  \"certifications\": null,\n",
      "  \"skills\": \"Problem Solving, Negotiation, Collaboration, Site Safety, Analysis\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Construction Project Manager at Walsh Group (2014 - current), Construction Project Manager at Skyline Restoration (2012 - 2014), Assistant Construction Project Manager at King Rose Construction (2008 - 2012)\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"Nivetha\",\n",
      "  \"email\": \"youremail@gmail.com\",\n",
      "  \"phone_number\": \"+92 330-872-8087\",\n",
      "  \"location\": \"Plot 2-5/14, Jr Colony\",\n",
      "  \"primary_skill\": \"Data Engineer\",\n",
      "  \"experience_years\": 6,\n",
      "  \"education\": \"AMT\",\n",
      "  \"certifications\": null,\n",
      "  \"skills\": null,\n",
      "  \"languages\": \"English, French, Tamil\",\n",
      "  \"previous_experience\": \"Accenture, IBM, Deloitte\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"Jennifer DuBois\",\n",
      "  \"email\": \"Jennifer@dubois.com\",\n",
      "  \"phone_number\": null,\n",
      "  \"location\": \"Vancouver, British Columbia, Canada\",\n",
      "  \"primary_skill\": \"IT-Focused Project Manager\",\n",
      "  \"experience_years\": 7,\n",
      "  \"education\": \"Bachelor's in Business Administration, minor in Computer Science, British Columbia Institute of Technology, 08/2006 - 05/2010, Vancouver, Canada\",\n",
      "  \"certifications\": \"Project Management Professional Certification (02/2016), Awarded by the Project Management Institute; University of California at Berkeley Coding Certificate (05/2011 - 11/2011), 24-week course in HTML 5, CSS 3, Javascript, MySQL, and Python\",\n",
      "  \"skills\": \"Web Development, Marketing, Accounting, Project Management, Software, Database Management, Documentation, Microsoft Office\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Project Manager at Amazon (07/2016 - Present, Seattle, Washington); Project Manager at Visier Solutions (11/2012 - 07/2016, Vancouver, British Columbia); Administrative Assistant at Visier Solutions (02/2011 - 11/2012); Front Desk Agent at Marriott Hotel (07/2004 - 08/2006, Whistler, British Columbia)\",\n",
      "  \"projects\": \"Spearheaded Amazon Alexa Data Services development project; Led Visier People's Talent Acquisition software development project\"\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"Suzan Kihn\",\n",
      "  \"email\": \"suzankihn@gmail.com\",\n",
      "  \"phone_number\": \"(613) 9003481\",\n",
      "  \"location\": \"Port Laury, 85387, Wisconsin\",\n",
      "  \"primary_skill\": \"Front End Web Developer\",\n",
      "  \"experience_years\": 2,\n",
      "  \"education\": \"Bachelor of Science in Computer Science University of California, Berkeley 2017 - 2021\",\n",
      "  \"certifications\": null,\n",
      "  \"skills\": \"HTML/CSS - Expert, JavaScript - Expert, jQuery - Expert, React/Vue - Expert, AJAX - Expert, Bootstrap - Expert\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Front End Web Developer, Wilkinson and Sons; Front End Web Developer, Romaguera LLC\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"MADISON TAYLOR\",\n",
      "  \"email\": \"help@enhancv.com\",\n",
      "  \"phone_number\": \"+1-(234)-555-1234\",\n",
      "  \"location\": \"New York City, New York\",\n",
      "  \"primary_skill\": \"Experienced Sales Professional\",\n",
      "  \"experience_years\": 7,\n",
      "  \"education\": \"Master of Business Administration from New York University Stern School of Business; Bachelor of Science in Marketing from Rutgers University\",\n",
      "  \"certifications\": \"Advanced Sales Strategies Certification; Salesforce CRM Power User Course\",\n",
      "  \"skills\": \"B2C Sales, Client Relationship Management, Salesforce CRM, Microsoft Office Suite, Google Suite, Strategic Planning\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Senior Sales Consultant at Luxury Auto Group; Sales Representative at Tech Solutions Inc.; Account Manager at Insurance Co\",\n",
      "  \"projects\": \"Launch of High-Impact Sales Initiative\"\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"ELIJAH BROWN\",\n",
      "  \"email\": \"help@enhancv.com\",\n",
      "  \"phone_number\": \"+1-(234)-555-1234\",\n",
      "  \"location\": \"Los Angeles, California\",\n",
      "  \"primary_skill\": \"Senior Project Coordinator\",\n",
      "  \"experience_years\": 10,\n",
      "  \"education\": \"Master of Business Administration, University of Southern California, 01/2014 - 01/2016; Bachelor of Science in Civil Engineering, University of California, Los Angeles, 01/2006 - 01/2010\",\n",
      "  \"certifications\": \"PMP Certification\",\n",
      "  \"skills\": \"Project Management, Data Analysis, Risk Management, Resource Allocation, Budget Management, Scheduling Software, Microsoft Project, Primavera P6, Quality Control, Contract Management, Stakeholder Communication, Cost Estimation\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Senior Project Coordinator at AECOM, Project Manager at Jacobs Engineering Group, Project Coordinator at Fluor Corporation\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"Delbe Kuval\",\n",
      "  \"email\": \"delbekuval@gmail.com\",\n",
      "  \"phone_number\": \"(497) 9512254\",\n",
      "  \"location\": \"North Erynfort, 68553-7473, Kentucky\",\n",
      "  \"primary_skill\": \"Construction Project Manager\",\n",
      "  \"experience_years\": 10,\n",
      "  \"education\": \"Bachelor of Science in Construction Management University of Southern California 2017 - 2021\",\n",
      "  \"certifications\": null,\n",
      "  \"skills\": \"Project Planning - Expert, Budget Management - Expert, Risk Management - Expert, Team Leadership - Expert, Contract Negotiation - Expert, Quality Control - Expert\",\n",
      "  \"languages\": null,\n",
      "  \"previous_experience\": \"Construction Project Manager, Brakus Inc; Construction Project Manager, Durgan Inc\",\n",
      "  \"projects\": null\n",
      "}\n",
      ":white_check_mark: Generated schema: ResumeDataExtraction\n",
      ":clipboard: Fields: 12 (all optional)\n",
      ":thought_balloon: Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: ResumeDataExtraction\n",
      "Context: Extract structured data from noisy OCR output of resumes.\n",
      "Reasoning: This schema captures essential information from resumes, allowing for structured data extraction from noisy OCR outputs. Each field is optional to accommodate varying levels of detail in resumes.\n",
      "\n",
      "Fields:\n",
      "  • name: Optional[string]\n",
      "    └─ Full name of the candidate\n",
      "  • email: Optional[string]\n",
      "    └─ Email address of the candidate\n",
      "  • phone_number: Optional[string]\n",
      "    └─ Contact phone number of the candidate\n",
      "  • location: Optional[string]\n",
      "    └─ Current location of the candidate\n",
      "  • primary_skill: Optional[string]\n",
      "    └─ Main skill or job title of the candidate\n",
      "  • experience_years: Optional[int]\n",
      "    └─ Total years of relevant work experience\n",
      "  • education: Optional[string]\n",
      "    └─ Educational background of the candidate\n",
      "  • certifications: Optional[string]\n",
      "    └─ List of certifications obtained by the candidate\n",
      "  • skills: Optional[array]\n",
      "    └─ List of skills and techniques possessed by the candidate\n",
      "  • languages: Optional[array]\n",
      "    └─ Languages spoken by the candidate\n",
      "  • previous_experience: Optional[array]\n",
      "    └─ List of previous job titles and companies\n",
      "  • projects: Optional[array]\n",
      "    └─ List of significant projects worked on by the candidate\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"name\": \"First Last\",\n",
      "  \"email\": \"jack.johnson@gmail.com\",\n",
      "  \"phone_number\": \"+44 07701235678\",\n",
      "  \"location\": \"London, United Kingdom\",\n",
      "  \"primary_skill\": \"Azure Data Engineer\",\n",
      "  \"experience_years\": 5,\n",
      "  \"education\": \"Bachelor of Science in Information Technology (Data Science) from University of New York, New York City, New York\",\n",
      "  \"certifications\": \"Databricks Certification and Badging (2022), Microsoft Certified: Azure Data Engineer Associate (2021)\",\n",
      "  \"skills\": \"Data Visualisation, Data Migration, Analytical Problem-Solving, Domain Knowledge, Project Management, Software Development, Azure Data Lake, Azure Databricks, Azure SQL Data Warehouse, Python, MS Business Intelligence, Programming Scala\",\n",
      "  \"languages\": \"English (Native), Afrikaans (Native), Arabic (Conversational)\",\n",
      "  \"previous_experience\": \"Business Analyst at ABC Company, London, UK; Systems Engineer at XYZ Company, New York, USA; Server Team Data Engineer (Internship) at ABC, New York, USA\",\n",
      "  \"projects\": \"Analyzed, designed and built data solutions for 12 enterprise level businesses; Created a Build and Release process for 25+ projects using Amazon Web Services Cloud9; Led the Content Delivery Network (CDN) expansion; Designed an internal website for 150+ personnel\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "gold_data = [extracted_data]\n",
    "for image_ocr_markdown in image_ocr_markdowna[1:]:\n",
    "    # Usage Example\n",
    "    sample_flight_ocr =image_ocr_markdown\n",
    "    # Initialize the utility (you'll need to define these variables)\n",
    "    FUELIX_API_KEY = fuelix_api_key#\"your-fuelix-api-key-here\"\n",
    "    SCHEMA_MODEL = \"gpt-4o-mini\"  # or whatever model you want to use\n",
    "\n",
    "    extractor = DocumentExtractionUtility(FUELIX_API_KEY, SCHEMA_MODEL)\n",
    "\n",
    "    # Define context\n",
    "    context = \"Sharing noisey OCR output of booking confirmation for customer service purposes - need passenger names,age etc (if present in the input) for support ticket resolution\"\n",
    "\n",
    "    try:\n",
    "        # Process the document\n",
    "        schema, extracted_data = extractor.process_document(context, sample_flight_ocr,schema)\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "        print(\"GENERATED SCHEMA:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Model Name: {schema.model_name}\")\n",
    "        print(f\"Context: {schema.context_purpose}\")\n",
    "        print(f\"Reasoning: {schema.reasoning}\")\n",
    "        print(\"\\nFields:\")\n",
    "        for field in schema.fields:\n",
    "            alias_info = f\" (alias: {field.alias})\" if field.alias else \"\"\n",
    "            print(f\"  • {field.name}: {field.field_type}{alias_info}\")\n",
    "            print(f\"    └─ {field.description}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"EXTRACTED DATA:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(extracted_data.model_dump_json(indent=2))\n",
    "        gold_data.append(extracted_data)\n",
    "    except Exception as e:\n",
    "        print(f\":x: Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a9701df-caa0-4928-b643-6074063fe444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for 14 resumes...\n",
      "✓ Embedded resume: resume_000\n",
      "✓ Embedded resume: resume_001\n",
      "✓ Embedded resume: resume_002\n",
      "✓ Embedded resume: resume_003\n",
      "✓ Embedded resume: resume_004\n",
      "✓ Embedded resume: resume_005\n",
      "✓ Embedded resume: resume_006\n",
      "✓ Embedded resume: resume_007\n",
      "✓ Embedded resume: resume_008\n",
      "✓ Embedded resume: resume_009\n",
      "✓ Embedded resume: resume_010\n",
      "✓ Embedded resume: resume_011\n",
      "✓ Embedded resume: resume_012\n",
      "✓ Embedded resume: resume_013\n",
      "✓ Saved embeddings to resume_embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict, Tuple\n",
    "import pickle\n",
    "\n",
    "class ResumeVectorSearch:\n",
    "    def __init__(self, fuelix_api_key: str):\n",
    "        self.client = OpenAI(\n",
    "            base_url='https://api-beta.fuelix.ai/',\n",
    "            api_key=fuelix_api_key\n",
    "        )\n",
    "        self.embedding_model = \"text-embedding-3-large\"  # Best choice\n",
    "        self.resume_embeddings = {}\n",
    "        self.job_embeddings = {}\n",
    "    \n",
    "    def get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Get embedding for text using Fuel IX\"\"\"\n",
    "        response = self.client.embeddings.create(\n",
    "            model=self.embedding_model,\n",
    "            input=text\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    \n",
    "    def preprocess_resume(self, resume_text: str) -> str:\n",
    "        \"\"\"Standardize resume format for better matching\"\"\"\n",
    "        # You can customize this based on your resume structure\n",
    "        return f\"Resume: {resume_text.strip()}\"\n",
    "    \n",
    "    def preprocess_job_description(self, job_desc: str) -> str:\n",
    "        \"\"\"Standardize job description format\"\"\"\n",
    "        return f\"Job Description: {job_desc.strip()}\"\n",
    "    \n",
    "    def embed_resumes(self, resumes: Dict[str, str]) -> Dict[str, List[float]]:\n",
    "        \"\"\"Create embeddings for all resumes\"\"\"\n",
    "        print(f\"Creating embeddings for {len(resumes)} resumes...\")\n",
    "        \n",
    "        for resume_id, resume_text in resumes.items():\n",
    "            processed_text = self.preprocess_resume(resume_text)\n",
    "            embedding = self.get_embedding(processed_text)\n",
    "            self.resume_embeddings[resume_id] = embedding\n",
    "            print(f\"✓ Embedded resume: {resume_id}\")\n",
    "        \n",
    "        return self.resume_embeddings\n",
    "    \n",
    "    def embed_job_description(self, job_id: str, job_desc: str) -> List[float]:\n",
    "        \"\"\"Create embedding for job description\"\"\"\n",
    "        processed_text = self.preprocess_job_description(job_desc)\n",
    "        embedding = self.get_embedding(processed_text)\n",
    "        self.job_embeddings[job_id] = embedding\n",
    "        return embedding\n",
    "    \n",
    "    def find_matching_resumes(self, job_desc: str, top_k: int = 20, \n",
    "                            threshold: float = 0.6) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Find resumes that match the job description\"\"\"\n",
    "        \n",
    "        # Get job description embedding\n",
    "        job_embedding = self.get_embedding(self.preprocess_job_description(job_desc))\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = []\n",
    "        for resume_id, resume_embedding in self.resume_embeddings.items():\n",
    "            # Calculate cosine similarity\n",
    "            similarity = cosine_similarity(\n",
    "                [job_embedding], \n",
    "                [resume_embedding]\n",
    "            )[0][0]\n",
    "            \n",
    "            if similarity >= threshold:\n",
    "                similarities.append((resume_id, similarity))\n",
    "        \n",
    "        # Sort by similarity (highest first) and return top_k\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:top_k]\n",
    "    \n",
    "    def save_embeddings(self, filepath: str):\n",
    "        \"\"\"Save embeddings to file\"\"\"\n",
    "        data = {\n",
    "            'resume_embeddings': self.resume_embeddings,\n",
    "            'job_embeddings': self.job_embeddings,\n",
    "            'model': self.embedding_model\n",
    "        }\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"✓ Saved embeddings to {filepath}\")\n",
    "    \n",
    "    def load_embeddings(self, filepath: str):\n",
    "        \"\"\"Load embeddings from file\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        self.resume_embeddings = data['resume_embeddings']\n",
    "        self.job_embeddings = data['job_embeddings']\n",
    "        self.embedding_model = data['model']\n",
    "        print(f\"✓ Loaded {len(self.resume_embeddings)} resume embeddings\")\n",
    "\n",
    "# Usage Example\n",
    "FUELIX_API_KEY = fuelix_api_key\n",
    "\n",
    "# Sample resumes (in practice, you'd load from files/database)\n",
    "def json_to_resume_strings_oneliner(gold_data):\n",
    "    return {\n",
    "        f\"resume_{i:03d}\": \n",
    "        json.dumps(item.model_dump(), ensure_ascii=False)\n",
    "        .replace('{', '').replace('}', '').replace('\"', '')\n",
    "        .replace(',', ' ').replace(':', ' ') \n",
    "        for i, item in enumerate(gold_data)\n",
    "    }\n",
    "\n",
    "resumes =json_to_resume_strings_oneliner(gold_data)\n",
    "\n",
    "# Initialize search system\n",
    "search = ResumeVectorSearch(fuelix_api_key)\n",
    "\n",
    "# Create embeddings for all resumes\n",
    "search.embed_resumes(resumes)\n",
    "\n",
    "# Save embeddings for future use\n",
    "search.save_embeddings(\"resume_embeddings.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60b48318-baa4-4ace-9015-298d1e6eda06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MATCHING RESULTS:\n",
      "==================================================\n",
      "Resume: resume_009\n",
      "Similarity: 0.474 (Fair match)\n",
      "Preview: name  Suzan Kihn  email  suzankihn@gmail.com  phone_number  (613) 9003481  location  Port Laury  85387  Wisconsin  primary_skill  Front End Web Developer  experience_years  2  education  Bachelor of Science in Computer Science University of California  Berkeley 2017 - 2021  certifications  null  skills  HTML/CSS - Expert  JavaScript - Expert  jQuery - Expert  React/Vue - Expert  AJAX - Expert  Bootstrap - Expert  languages  null  previous_experience  Front End Web Developer  Wilkinson and Sons; Front End Web Developer  Romaguera LLC  projects  null...\n",
      "------------------------------\n",
      "Resume: resume_002\n",
      "Similarity: 0.459 (Fair match)\n",
      "Preview: name  Chris Wilkes  email  chris_wilkes99@gmail.com  phone_number  407-790-3421  location  Orlando  FL 32789  United States  primary_skill  Front End Developer  experience_years  8  education  Bachelor of Science in Computer Science  University of Central Florida  Orlando  certifications  null  skills  null  languages  null  previous_experience  Senior Front End Developer  IXF  Orlando; Front End Developer  Sasco Group  Orlando  projects  null...\n",
      "------------------------------\n",
      "Resume: resume_005\n",
      "Similarity: 0.355 (Fair match)\n",
      "Preview: name  James Jones  email  help@enhancv.com  phone_number  null  location  San Antonio  Texas  primary_skill  Senior Backend Software Engineer  experience_years  5  education  Master's degree in Computer Science  certifications  Advanced Database Systems  Machine Learning with Python  skills  Python  C++  AWS Services  SQL  MySQL  PostgreSQL  NoSQL databases  Atlassian JIRA  Confluence  Terraform  Git  CI/CD  Agile Methodologies  languages  null  previous_experience  Senior Backend Software Engineer at MedTech Solutions (2019 - 2022  London  United Kingdom); Backend Software Engineer at HealthTech Innovations (2017 - 2019  San Francisco  CA)  projects  Open Health Data API  Medical Data Visualization Tool...\n",
      "------------------------------\n",
      "Resume: resume_008\n",
      "Similarity: 0.338 (Fair match)\n",
      "Preview: name  Jennifer DuBois  email  Jennifer@dubois.com  phone_number  null  location  Vancouver  British Columbia  Canada  primary_skill  IT-Focused Project Manager  experience_years  7  education  Bachelor's in Business Administration  minor in Computer Science  British Columbia Institute of Technology  08/2006 - 05/2010  Vancouver  Canada  certifications  Project Management Professional Certification (02/2016)  Awarded by the Project Management Institute; University of California at Berkeley Coding Certificate (05/2011 - 11/2011)  24-week course in HTML 5  CSS 3  Javascript  MySQL  and Python  skills  Web Development  Marketing  Accounting  Project Management  Software  Database Management  Documentation  Microsoft Office  languages  null  previous_experience  Project Manager at Amazon (07/2016 - Present  Seattle  Washington); Project Manager at Visier Solutions (11/2012 - 07/2016  Vancouver  British Columbia); Administrative Assistant at Visier Solutions (02/2011 - 11/2012); Front Desk Agent at Marriott Hotel (07/2004 - 08/2006  Whistler  British Columbia)  projects  Spearheaded Amazon Alexa Data Services development project; Led Visier People's Talent Acquisition software development project...\n",
      "------------------------------\n",
      "Resume: resume_013\n",
      "Similarity: 0.338 (Fair match)\n",
      "Preview: name  First Last  email  jack.johnson@gmail.com  phone_number  +44 07701235678  location  London  United Kingdom  primary_skill  Azure Data Engineer  experience_years  5  education  Bachelor of Science in Information Technology (Data Science) from University of New York  New York City  New York  certifications  Databricks Certification and Badging (2022)  Microsoft Certified  Azure Data Engineer Associate (2021)  skills  Data Visualisation  Data Migration  Analytical Problem-Solving  Domain Knowledge  Project Management  Software Development  Azure Data Lake  Azure Databricks  Azure SQL Data Warehouse  Python  MS Business Intelligence  Programming Scala  languages  English (Native)  Afrikaans (Native)  Arabic (Conversational)  previous_experience  Business Analyst at ABC Company  London  UK; Systems Engineer at XYZ Company  New York  USA; Server Team Data Engineer (Internship) at ABC  New York  USA  projects  Analyzed  designed and built data solutions for 12 enterprise level businesses; Created a Build and Release process for 25+ projects using Amazon Web Services Cloud9; Led the Content Delivery Network (CDN) expansion; Designed an internal website for 150+ personnel...\n",
      "------------------------------\n",
      "Resume: resume_000\n",
      "Similarity: 0.325 (Fair match)\n",
      "Preview: name  First Last  email  jack.johnson@gmail.com  phone_number  +44 07701235678  location  London  United Kingdom  primary_skill  Azure Data Engineer  experience_years  5  education  Bachelor of Science in Information Technology (Data Science) from University of New York  New York City  New York (11/2012 - 07/2015)  certifications  Databricks Certification and Badging (2022)  Microsoft Certified  Azure Data Engineer Associate (2021)  skills  Data Visualisation  Data Migration  Analytical Problem-Solving  Domain Knowledge  Project Management  Software Development  Azure Data Lake  Azure Databricks  Azure SQL Data Warehouse  Python  MS Business Intelligence  Programming Scala  languages  English (Native)  Afrikaans (Native)  Arabic (Conversational)  previous_experience  Business Analyst  ABC Company  London  UK; Systems Engineer  XYZ Company  New York  USA; Server Team Data Engineer (Internship)  ABC  New York  USA (06/2017 - 05/2018  06/2016 - 05/2017  09/2014 - 05/2015)  projects  Analyzed  designed and built data solutions for 12 enterprise level businesses; Developed SQL scripts for query automation; Created a Build and Release process for 25+ projects; Delivered training presentations to 250+ staff; Supported 15+ product managers and software engineers; Led the Content Delivery Network (CDN) expansion; Designed an internal website for 150+ personnel; Collaborated with five departments; Joined a ten-person product team....\n",
      "------------------------------\n",
      "Resume: resume_007\n",
      "Similarity: 0.322 (Fair match)\n",
      "Preview: name  Nivetha  email  youremail@gmail.com  phone_number  +92 330-872-8087  location  Plot 2-5/14  Jr Colony  primary_skill  Data Engineer  experience_years  6  education  AMT  certifications  null  skills  null  languages  English  French  Tamil  previous_experience  Accenture  IBM  Deloitte  projects  null...\n",
      "------------------------------\n",
      "Resume: resume_003\n",
      "Similarity: 0.284 (Fair match)\n",
      "Preview: name  ALAN SUSA  email  alansusa@email.com  phone_number  (123) 456-7890  location  New York  NY  primary_skill  Data Engineer  experience_years  9  education  B.A. in Computer Science from University of Pittsburgh (September 2010 - April 2014)  certifications  null  skills  Python  ETLs  SQL (Postgres  Redshift  MySQL)  NoSQL (MongoDB)  Spark  Kafka  Airflow  AWS (Athena  Lambda  S3)  languages  null  previous_experience  Data Engineer at Consumer Reports  Data Engineer at Guardian Life Insurance Company  Data Engineer Intern at Federal Reserve Board of Governors  projects  null...\n",
      "------------------------------\n",
      "Resume: resume_012\n",
      "Similarity: 0.279 (Fair match)\n",
      "Preview: name  Delbe Kuval  email  delbekuval@gmail.com  phone_number  (497) 9512254  location  North Erynfort  68553-7473  Kentucky  primary_skill  Construction Project Manager  experience_years  10  education  Bachelor of Science in Construction Management University of Southern California 2017 - 2021  certifications  null  skills  Project Planning - Expert  Budget Management - Expert  Risk Management - Expert  Team Leadership - Expert  Contract Negotiation - Expert  Quality Control - Expert  languages  null  previous_experience  Construction Project Manager  Brakus Inc; Construction Project Manager  Durgan Inc  projects  null...\n",
      "------------------------------\n",
      "Resume: resume_004\n",
      "Similarity: 0.279 (Fair match)\n",
      "Preview: name  Meera Patel  email  meerapatel@example.com  phone_number  (720) 555-5678  location  San Diego  CA 92102  primary_skill  Inside Sales  experience_years  2  education  Bachelor of Science in Marketing from University of San Diego at San Diego  CA  certifications  null  skills  Cold calling  Consultative selling  Inside sales  Lead qualification  Salesforce CRM  languages  null  previous_experience  Inside Sales Representative at Decker Software  San Diego  CA; Inside Sales Representative at State Farm Insurance  San Diego  CA  projects  null...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Job description to match against\n",
    "job_description = \"\"\"\n",
    "Front End Developer\n",
    "Looking for 3+ years experience in HTML & Javascript and CSS\n",
    "Required skills: UI-Ux Frontend Dev\n",
    "Responsible for building and website-app frontends\n",
    "\"\"\"\n",
    "\n",
    "# Find matching resumes\n",
    "matches = search.find_matching_resumes(job_description, top_k=10, threshold=0.0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MATCHING RESULTS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for resume_id, similarity in matches:\n",
    "    match_strength = \"Strong\" if similarity > 0.8 else \"Moderate\" if similarity > 0.7 else \"Fair\"\n",
    "    print(f\"Resume: {resume_id}\")\n",
    "    print(f\"Similarity: {similarity:.3f} ({match_strength} match)\")\n",
    "    print(f\"Preview: {resumes[resume_id][:]}...\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a46bd824-19c3-44ae-8317-511f061fdfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"HI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeccfe7-69d3-446d-b560-a3bc49f3710c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

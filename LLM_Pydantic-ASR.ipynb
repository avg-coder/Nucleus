{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d0b8f8-9f94-4952-ad71-d2d8fdff8ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mistralai\n",
      "  Downloading mistralai-1.9.10-py3-none-any.whl (440 kB)\n",
      "\u001b[K     |████████████████████████████████| 440 kB 28.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting eval-type-backport>=0.2.0\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in /home/jovyan/.local/lib/python3.9/site-packages (from mistralai) (2.11.9)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 169.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-inspection>=0.4.0 in /home/jovyan/.local/lib/python3.9/site-packages (from mistralai) (0.4.1)\n",
      "Collecting invoke<3.0.0,>=2.2.0\n",
      "  Downloading invoke-2.2.0-py3-none-any.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 176.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml<7.0.0,>=6.0.2\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
      "\u001b[K     |████████████████████████████████| 737 kB 163.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.28.1 in /home/jovyan/.local/lib/python3.9/site-packages (from mistralai) (0.28.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.9/site-packages (from httpx>=0.28.1->mistralai) (3.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx>=0.28.1->mistralai) (2021.5.30)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.9/site-packages (from httpx>=0.28.1->mistralai) (2.10)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.local/lib/python3.9/site-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/.local/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/jovyan/.local/lib/python3.9/site-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jovyan/.local/lib/python3.9/site-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/jovyan/.local/lib/python3.9/site-packages (from pydantic>=2.10.3->mistralai) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->mistralai) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio->httpx>=0.28.1->mistralai) (1.2.0)\n",
      "Installing collected packages: pyyaml, python-dateutil, invoke, eval-type-backport, mistralai\n",
      "\u001b[33m  WARNING: The scripts inv and invoke are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed eval-type-backport-0.2.2 invoke-2.2.0 mistralai-1.9.10 python-dateutil-2.9.0.post0 pyyaml-6.0.2\n",
      "Collecting instructor\n",
      "  Downloading instructor-1.11.3-py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 27.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docstring-parser<1.0,>=0.16\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Collecting typer<1.0.0,>=0.9.0\n",
      "  Downloading typer-0.17.4-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 7.7 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting diskcache>=5.6.3\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 6.9 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3.0.0,>=2.32.3\n",
      "  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 6.4 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting rich<15.0.0,>=13.7.0\n",
      "  Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 160.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.9.1\n",
      "  Downloading aiohttp-3.12.15-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 160.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2<4.0.0,>=3.1.4\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 179.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting openai<2.0.0,>=1.70.0\n",
      "  Downloading openai-1.107.2-py3-none-any.whl (946 kB)\n",
      "\u001b[K     |████████████████████████████████| 946 kB 143.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jiter<0.11,>=0.6.1\n",
      "  Downloading jiter-0.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
      "\u001b[K     |████████████████████████████████| 353 kB 140.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /home/jovyan/.local/lib/python3.9/site-packages (from instructor) (2.33.2)\n",
      "Collecting tenacity<10.0.0,>=8.2.3\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /home/jovyan/.local/lib/python3.9/site-packages (from instructor) (2.11.9)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (6.0.2)\n",
      "Collecting aiosignal>=1.4.0\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.20.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "\u001b[K     |████████████████████████████████| 327 kB 159.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.3.3)\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 164.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2 in /home/jovyan/.local/lib/python3.9/site-packages (from aiosignal>=1.4.0->aiohttp<4.0.0,>=3.9.1->instructor) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2<4.0.0,>=3.1.4->instructor) (2.1.2)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jovyan/.local/lib/python3.9/site-packages (from openai<2.0.0,>=1.70.0->instructor) (0.28.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.9/site-packages (from openai<2.0.0,>=1.70.0->instructor) (4.51.0)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 161.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from openai<2.0.0,>=1.70.0->instructor) (1.2.0)\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.70.0->instructor) (2.10)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.local/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.70.0->instructor) (1.0.9)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.70.0->instructor) (2021.5.30)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/.local/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.70.0->instructor) (0.16.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/jovyan/.local/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.8.0->instructor) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jovyan/.local/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.8.0->instructor) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.32.3->instructor) (1.25.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.32.3->instructor) (2.0.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 12.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 147.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from typer<1.0.0,>=0.9.0->instructor) (8.0.1)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: mdurl, exceptiongroup, pygments, propcache, markdown-it-py, anyio, yarl, shellingham, rich, jiter, distro, aiosignal, aiohappyeyeballs, typer, tenacity, requests, openai, jinja2, docstring-parser, diskcache, aiohttp, instructor\n",
      "\u001b[33m  WARNING: The script pygmentize is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script markdown-it is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script distro is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script typer is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script openai is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script instructor is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 1.10.2 requires anyio<4,>=3.1.0, but you have anyio 4.10.0 which is incompatible.\u001b[0m\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 anyio-4.10.0 diskcache-5.6.3 distro-1.9.0 docstring-parser-0.17.0 exceptiongroup-1.3.0 instructor-1.11.3 jinja2-3.1.6 jiter-0.10.0 markdown-it-py-3.0.0 mdurl-0.1.2 openai-1.107.2 propcache-0.3.2 pygments-2.19.2 requests-2.32.5 rich-14.1.0 shellingham-1.5.4 tenacity-9.1.2 typer-0.17.4 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mistralai --user\n",
    "!pip install instructor  --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a19b4d-fd59-4ddb-b74a-db0a6b7308e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "MISTRAL_API_KEY=os.getenv(\"MISTRAL_API_KEY\")\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "fuelix_api_key =  os.getenv(\"FUELIX_API_KEY\")\n",
    "\n",
    "from mistralai import Mistral\n",
    "from mistralai import TextChunk\n",
    "import os\n",
    "from instructor import from_mistral, Mode\n",
    "from datetime import datetime,date\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a5094b-8e43-4378-8593-8e3de475893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elevenlabs in /home/jovyan/.local/lib/python3.9/site-packages (2.15.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /home/jovyan/.local/lib/python3.9/site-packages (from elevenlabs) (2.11.9)\n",
      "Requirement already satisfied: requests>=2.20 in /home/jovyan/.local/lib/python3.9/site-packages (from elevenlabs) (2.32.5)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /home/jovyan/.local/lib/python3.9/site-packages (from elevenlabs) (4.15.0)\n",
      "Requirement already satisfied: websockets>=11.0 in /home/jovyan/.local/lib/python3.9/site-packages (from elevenlabs) (15.0.1)\n",
      "Requirement already satisfied: pydantic-core>=2.18.2 in /home/jovyan/.local/lib/python3.9/site-packages (from elevenlabs) (2.33.2)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /home/jovyan/.local/lib/python3.9/site-packages (from elevenlabs) (0.28.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.local/lib/python3.9/site-packages (from httpx>=0.21.2->elevenlabs) (1.0.9)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx>=0.21.2->elevenlabs) (2021.5.30)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.9/site-packages (from httpx>=0.21.2->elevenlabs) (2.10)\n",
      "Requirement already satisfied: anyio in /home/jovyan/.local/lib/python3.9/site-packages (from httpx>=0.21.2->elevenlabs) (4.10.0)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/.local/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.21.2->elevenlabs) (0.16.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/jovyan/.local/lib/python3.9/site-packages (from pydantic>=1.9.2->elevenlabs) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jovyan/.local/lib/python3.9/site-packages (from pydantic>=1.9.2->elevenlabs) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->elevenlabs) (1.25.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.20->elevenlabs) (2.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/jovyan/.local/lib/python3.9/site-packages (from anyio->httpx>=0.21.2->elevenlabs) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio->httpx>=0.21.2->elevenlabs) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd7c570-140a-41b0-a455-0c36909d1163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎧 Transcribing audio1.wav ...\n",
      "✅ Transcription saved to word_level_output.json\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "import uuid\n",
    "import json\n",
    "from pathlib import Path\n",
    "from elevenlabs import ElevenLabs\n",
    "\n",
    "# ------------------------\n",
    "# Config\n",
    "# ------------------------\n",
    "ELEVENLABS_API_KEY =os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "elevenlabs = ElevenLabs(api_key=ELEVENLABS_API_KEY)\n",
    "\n",
    "# ------------------------\n",
    "# Helper: ElevenLabs transcription\n",
    "# ------------------------\n",
    "def transcribe_with_elevenlabs(audio_path: Path):\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        transcription = elevenlabs.speech_to_text.convert(\n",
    "            file=f,\n",
    "            model_id=\"scribe_v1\",\n",
    "            diarize=True,\n",
    "            timestamps_granularity=\"word\",  # word-level timestamps\n",
    "            tag_audio_events=False\n",
    "        )\n",
    "\n",
    "    # Convert ElevenLabs model object to dict\n",
    "    if hasattr(transcription, \"dict\"):\n",
    "        transcription = transcription.dict()\n",
    "    elif hasattr(transcription, \"model_dump\"):\n",
    "        transcription = transcription.model_dump()\n",
    "\n",
    "    return transcription\n",
    "\n",
    "# ------------------------\n",
    "# Clean & format words\n",
    "# ------------------------\n",
    "def build_word_level_json(transcription):\n",
    "    words = transcription.get(\"words\", [])\n",
    "    cleaned = []\n",
    "\n",
    "    skip_tokens = {\"\", \" \"}\n",
    "\n",
    "    for w in words:\n",
    "        word_text = w.get(\"text\", \"\").strip()\n",
    "        if word_text in skip_tokens:\n",
    "            continue\n",
    "\n",
    "        cleaned.append({\n",
    "            \"word\": word_text,\n",
    "            \"start_timestamp\": w.get(\"start\"),\n",
    "            \"end_timestamp\": w.get(\"end\")\n",
    "        })\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "# ------------------------\n",
    "# Main\n",
    "# ------------------------\n",
    "def process_audio(audio_path: str, output_json: str = \"transcription.json\"):\n",
    "    audio_path = Path(audio_path)\n",
    "    if not audio_path.exists():\n",
    "        raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
    "\n",
    "    print(f\"🎧 Transcribing {audio_path} ...\")\n",
    "    transcription = transcribe_with_elevenlabs(audio_path)\n",
    "    word_json = build_word_level_json(transcription)\n",
    "\n",
    "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(word_json, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ Transcription saved to {output_json}\")\n",
    "    return word_json\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Example Run\n",
    "# ------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # replace with your .wav file path\n",
    "    wav_file = \"audio1.wav\"\n",
    "    process_audio(wav_file, \"word_level_output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fb6d1d-a9ea-42f8-bcc3-dbe83154882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would this be for pickup or delivery? Um, pickup please. May I have your name? Tanisha. Tanisha? Yes. One moment please. Okay. May I have your good call back number please? I'm sorry, can you hear my what? I'm sorry. Uh, your phone number, your good call back number. Yes. 443-680-1162. Are you going to pick it up at the store in the 7106 Mint Railway Unit 6, in the same shopping center- Yeah. ... as Burger King, Subway, and Dunkin' Donuts? Yeah. What can I get for you today? Yes. Um, can I have a small, um, pepperoni pizza? Give me the, uh, personal pan. No, I just, I want a small size pepperoni pizza, not personal. Okay, uh, we don't have small. We only have personal pan and the medium one. Okay, I'll take the medium one then. Uh, what type of crust do you want? Is it hand sauce or thin crust? Um, pan please. Okay, one medium pan and what is your topping? Pepperoni. Okay, what else? That's it. How about our freshly baked triple chocolate brownie for dessert? No, thank you. Okay, would you like one personal pan with, uh, sorry, one medium original pan with pepperoni? Your total bill $18 including tax. Pickup time- Hold on. Did you say, did you say personal and medium? I only wanted one pizza, which is the medium. I don't want personal. One medium, one medium original pan with pepperoni. Yes. Okay. Okay, uh, 15 minutes the pickup time. Okay, uh, we're all set now. Thank you for choosing Pizza Hut. Have a great day. Bye. Thank you. You too. Bye-bye.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Open and read a JSON file\n",
    "with open(\"word_level_output.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Join and normalize text\n",
    "clean_text = \" \".join(\n",
    "    re.sub(r\"\\s+\", \" \", item[\"word\"]).strip()\n",
    "    for item in data\n",
    ")\n",
    "\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697d0833-44d5-4f04-bb77-bf9712cb046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ocr_markdown=clean_text #it should only contain text not timestamps (concatinate all the text in one string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e594d79-f2ed-4794-829b-b9258fe52206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from instructor import from_openai, Mode\n",
    "from openai import OpenAI\n",
    "from datetime import datetime, date\n",
    "from typing import Optional, List, Type, Any, get_origin, get_args\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "\n",
    "class FieldDefinition(BaseModel):\n",
    "    name: str\n",
    "    field_type: str  # \"str\", \"Optional[str]\", \"datetime\", \"Optional[datetime]\", etc.\n",
    "    description: str\n",
    "    alias: Optional[str] = None\n",
    "\n",
    "class DynamicSchema(BaseModel):\n",
    "    model_name: str\n",
    "    context_purpose: str\n",
    "    fields: List[FieldDefinition]\n",
    "    reasoning: str\n",
    "\n",
    "class DocumentExtractionUtility:\n",
    "    def __init__(self, fuelix_api_key: str, schema_model: str = \"gpt-4o-mini\"):\n",
    "        self.fuel_ix_client = from_openai(\n",
    "            OpenAI(\n",
    "                base_url='https://api-beta.fuelix.ai/', \n",
    "                api_key=fuelix_api_key\n",
    "            ),\n",
    "            mode=Mode.JSON\n",
    "        )\n",
    "        self.schema_model = schema_model\n",
    "\n",
    "    def _parse_field_type(self, type_str: str) -> tuple[Type, Any]:\n",
    "        \"\"\"Convert string type to actual Python type and ensure it's optional\"\"\"\n",
    "        type_str = type_str.strip()\n",
    "\n",
    "        # Handle Optional types\n",
    "        if type_str.startswith(\"Optional[\") and type_str.endswith(\"]\"):\n",
    "            inner_type = type_str[9:-1]  # Remove \"Optional[\" and \"]\"\n",
    "            base_type, _ = self._parse_field_type(inner_type)\n",
    "            return Optional[base_type], None\n",
    "\n",
    "        # Handle basic types\n",
    "        type_mapping = {\n",
    "            \"str\": str,\n",
    "            \"int\": int,\n",
    "            \"float\": float,\n",
    "            \"bool\": bool,\n",
    "            \"datetime\": datetime,\n",
    "            \"date\": date,\n",
    "        }\n",
    "\n",
    "        if type_str in type_mapping:\n",
    "            # Always wrap in Optional to ensure all fields are optional\n",
    "            return Optional[type_mapping[type_str]], None\n",
    "        else:\n",
    "            # Default to Optional[str] if unknown type\n",
    "            return Optional[str], None\n",
    "\n",
    "    def create_model_from_schema(self, schema: DynamicSchema) -> Type[BaseModel]:\n",
    "        \"\"\"Create a Pydantic model from schema definition with all fields optional\"\"\"\n",
    "        fields = {}\n",
    "\n",
    "        for field_def in schema.fields:\n",
    "            field_type, default_value = self._parse_field_type(field_def.field_type)\n",
    "\n",
    "            # Handle aliases\n",
    "            field_kwargs = {}\n",
    "            if field_def.alias:\n",
    "                field_kwargs['alias'] = field_def.alias\n",
    "\n",
    "            # All fields are now optional with None as default\n",
    "            fields[field_def.name] = (field_type, Field(None, description=field_def.description, **field_kwargs))\n",
    "\n",
    "        # Create the dynamic model\n",
    "        DynamicModel = create_model(schema.model_name, **fields)\n",
    "        return DynamicModel\n",
    "\n",
    "    def generate_schema(self, context: str, ocr_sample: str) -> DynamicSchema:\n",
    "        \"\"\"Generate extraction schema based on context and document sample\"\"\"\n",
    "\n",
    "        schema_prompt = f\"\"\"\n",
    "Context: {context}\n",
    "\n",
    "Sample Document OCR Output:\n",
    "{ocr_sample}\n",
    "\n",
    "Based on this context and document sample, define a comprehensive data extraction schema.\n",
    "\n",
    "Guidelines:\n",
    "- Use snake_case for field names\n",
    "- Available types: str, int, float, bool, datetime, date, Optional[str], Optional[int], Optional[datetime], etc.\n",
    "- ALL fields should be Optional[] - this is mandatory for flexible extraction\n",
    "- Use aliases for Python keywords (e.g., \"from\" should have alias)\n",
    "- Consider what fields would be most valuable for the given context\n",
    "- Include clear descriptions for each field\n",
    "- Avoid making big sentences as part of the output schema. We want objective, normalized (in database terms) details like list of names, address etc\n",
    "- Remember: Every single field must be Optional to handle cases where information might be missing\n",
    "\n",
    "Generate a schema with model name, context purpose, field definitions, and reasoning.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.fuel_ix_client.chat.completions.create(\n",
    "                model=self.schema_model,\n",
    "                response_model=DynamicSchema,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a schema generation expert. Generate clean, practical and objective schemas for document extraction. ALL FIELDS MUST BE OPTIONAL. Examples: Optional[str] for name, Optional[int] for age, Optional[str] for phone_number, Optional[str] for pnr\"},\n",
    "                    {\"role\": \"user\", \"content\": schema_prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_retries=5\n",
    "            )\n",
    "            \n",
    "            # Post-process to ensure all fields are optional\n",
    "            for field in response.fields:\n",
    "                if not field.field_type.startswith(\"Optional[\"):\n",
    "                    # Wrap non-optional types in Optional\n",
    "                    field.field_type = f\"Optional[{field.field_type}]\"\n",
    "            \n",
    "            return response\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Schema generation failed: {str(e)}\")\n",
    "\n",
    "    def extract_data(self, DynamicModel, ocr_text: str) -> BaseModel:\n",
    "        \"\"\"Extract data using the generated schema\"\"\"\n",
    "\n",
    "        extraction_prompt = f\"\"\"\n",
    "Extract the following information from this document:\n",
    "\n",
    "Document OCR Text:\n",
    "{ocr_text}\n",
    "\n",
    "Extract all available fields. Use None/null for missing information.\n",
    "All fields are optional, so don't worry if some information is not present in the document.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            extraction_response = self.fuel_ix_client.chat.completions.create(\n",
    "                model=self.schema_model,\n",
    "                response_model=DynamicModel,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a data extraction expert. Extract information accurately from documents. Set fields to None if information is not available.\"},\n",
    "                    {\"role\": \"user\", \"content\": extraction_prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_retries=5\n",
    "            )\n",
    "            return extraction_response\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Data extraction failed: {str(e)}\")\n",
    "\n",
    "    def process_document(self, context: str, ocr_text: str, schema=None) -> tuple[DynamicSchema, BaseModel]:\n",
    "        \"\"\"Complete pipeline: generate schema and extract data\"\"\"\n",
    "        if not schema:\n",
    "            print(\":arrows_counterclockwise: Generating extraction schema...\")\n",
    "            schema = self.generate_schema(context, ocr_text)\n",
    "\n",
    "        print(f\":white_check_mark: Generated schema: {schema.model_name}\")\n",
    "        print(f\":clipboard: Fields: {len(schema.fields)} (all optional)\")\n",
    "        print(f\":thought_balloon: Reasoning: {schema.reasoning}\")\n",
    "        print()\n",
    "\n",
    "        print(\":arrows_counterclockwise: Extracting data...\")\n",
    "        DynamicModel = self.create_model_from_schema(schema)\n",
    "\n",
    "        extracted_data = self.extract_data(DynamicModel, ocr_text)\n",
    "\n",
    "        print(\":white_check_mark: Data extraction complete!\")\n",
    "\n",
    "        return schema, extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf22d2e-4ac2-4e81-b788-99673496a976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":arrows_counterclockwise: Generating extraction schema...\n",
      ":white_check_mark: Generated schema: PIIExtractionSchema\n",
      ":clipboard: Fields: 5 (all optional)\n",
      ":thought_balloon: Reasoning: This schema is designed to capture various types of PII from audio transcriptions, allowing for flexible extraction of multiple entries for names, phone numbers, addresses, emails, and any other relevant information.\n",
      "\n",
      ":arrows_counterclockwise: Extracting data...\n",
      ":white_check_mark: Data extraction complete!\n",
      "==================================================\n",
      "GENERATED SCHEMA:\n",
      "==================================================\n",
      "Model Name: PIIExtractionSchema\n",
      "Context: To extract and categorize Personally Identifiable Information (PII) from noisy audio transcription outputs.\n",
      "Reasoning: This schema is designed to capture various types of PII from audio transcriptions, allowing for flexible extraction of multiple entries for names, phone numbers, addresses, emails, and any other relevant information.\n",
      "\n",
      "Fields:\n",
      "  • names: Optional[list]\n",
      "    └─ List of names extracted from the transcription.\n",
      "  • phone_numbers: Optional[list]\n",
      "    └─ List of phone numbers extracted from the transcription.\n",
      "  • addresses: Optional[list]\n",
      "    └─ List of addresses extracted from the transcription.\n",
      "  • emails: Optional[list]\n",
      "    └─ List of email addresses extracted from the transcription.\n",
      "  • miscellaneous_pii: Optional[list]\n",
      "    └─ List of miscellaneous PII that does not fall into standard categories.\n",
      "\n",
      "==================================================\n",
      "EXTRACTED DATA:\n",
      "==================================================\n",
      "{\n",
      "  \"names\": \"Tanisha\",\n",
      "  \"phone_numbers\": \"443-680-1162\",\n",
      "  \"addresses\": \"7106 Mint Railway Unit 6\",\n",
      "  \"emails\": null,\n",
      "  \"miscellaneous_pii\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Usage Example\n",
    "# Sample OCR text (flight booking confirmation)\n",
    "sample_flight_ocr =image_ocr_markdown\n",
    "\n",
    "# Initialize the utility (you'll need to define these variables)\n",
    "FUELIX_API_KEY = \"ak-iN11LJkKQtOfT9681j90ICZ9dzAt\"#\"your-fuelix-api-key-here\"\n",
    "SCHEMA_MODEL = \"gpt-4o-mini\"  # or whatever model you want to use\n",
    "\n",
    "extractor = DocumentExtractionUtility(FUELIX_API_KEY, SCHEMA_MODEL)\n",
    "\n",
    "# Define context\n",
    "context = \"You are given noisy audio transcription output. Design schemas that can categorize and identify different types of Personally Identifiable Information (PII) which are names, phone numbers, addresses, emails only. Ensure the schema also includes a field for miscellaneous PII that may not fall into the standard categories, there can be multiple names, addresses,etc. schema should allow storing multiple names, addresses,etc for example name should be a LIST of strings like ['Anand Gurung','Anand]']\"\n",
    "\n",
    "try:\n",
    "    # Process the document\n",
    "    schema, extracted_data = extractor.process_document(context, sample_flight_ocr)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"GENERATED SCHEMA:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Model Name: {schema.model_name}\")\n",
    "    print(f\"Context: {schema.context_purpose}\")\n",
    "    print(f\"Reasoning: {schema.reasoning}\")\n",
    "    print(\"\\nFields:\")\n",
    "    for field in schema.fields:\n",
    "        alias_info = f\" (alias: {field.alias})\" if field.alias else \"\"\n",
    "        print(f\"  • {field.name}: {field.field_type}{alias_info}\")\n",
    "        print(f\"    └─ {field.description}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"EXTRACTED DATA:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(extracted_data.model_dump_json(indent=2))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\":x: Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5356aae-f091-400b-b6dc-ec63150cca3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSchema(model_name='PIIExtractionSchema', context_purpose='To extract and categorize Personally Identifiable Information (PII) from noisy audio transcription outputs.', fields=[FieldDefinition(name='names', field_type='Optional[list]', description='List of names extracted from the transcription.', alias=None), FieldDefinition(name='phone_numbers', field_type='Optional[list]', description='List of phone numbers extracted from the transcription.', alias=None), FieldDefinition(name='addresses', field_type='Optional[list]', description='List of addresses extracted from the transcription.', alias=None), FieldDefinition(name='emails', field_type='Optional[list]', description='List of email addresses extracted from the transcription.', alias=None), FieldDefinition(name='miscellaneous_pii', field_type='Optional[list]', description='List of miscellaneous PII that does not fall into standard categories.', alias=None)], reasoning='This schema is designed to capture various types of PII from audio transcriptions, allowing for flexible extraction of multiple entries for names, phone numbers, addresses, emails, and any other relevant information.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a0488b-9049-4d48-b96d-85e60297211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export schema to JSON file (2 lines)\n",
    "import json\n",
    "with open('schema.json', 'w') as f: json.dump(schema.model_dump(), f, indent=2)\n",
    "\n",
    "# Import schema from JSON file (2 lines)  \n",
    "with open('schema.json', 'r') as f: schema_dict = json.load(f)\n",
    "schema = DynamicSchema(**schema_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3d72b16-5b66-45df-abaa-74ff95f7a6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicSchema(model_name='PIIExtractionSchema', context_purpose='To extract and categorize Personally Identifiable Information (PII) from noisy audio transcription outputs.', fields=[FieldDefinition(name='names', field_type='Optional[list]', description='List of names extracted from the transcription.', alias=None), FieldDefinition(name='phone_numbers', field_type='Optional[list]', description='List of phone numbers extracted from the transcription.', alias=None), FieldDefinition(name='addresses', field_type='Optional[list]', description='List of addresses extracted from the transcription.', alias=None), FieldDefinition(name='emails', field_type='Optional[list]', description='List of email addresses extracted from the transcription.', alias=None), FieldDefinition(name='miscellaneous_pii', field_type='Optional[list]', description='List of miscellaneous PII that does not fall into standard categories.', alias=None)], reasoning='This schema is designed to capture various types of PII from audio transcriptions, allowing for flexible extraction of multiple entries for names, phone numbers, addresses, emails, and any other relevant information.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4ce92-9c73-4fab-af0d-bb98aa1154e7",
   "metadata": {},
   "source": [
    "# Using The Schema Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a34fd4-cfed-41b9-a90b-43ceed8fa68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIIExtractionSchema(names='Tanisha', phone_numbers='443-680-1162', addresses='7106 Mint Railway Unit 6', emails=None, miscellaneous_pii=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f6ecdcf-9995-40ba-ae46-2c9b165c3359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start_timestamp': 10.18, 'end_timestamp': 12.2}, {'start_timestamp': 12.24, 'end_timestamp': 14.14}, {'start_timestamp': 29.48, 'end_timestamp': 34.02}, {'start_timestamp': 36.86, 'end_timestamp': 37.66}, {'start_timestamp': 37.72, 'end_timestamp': 37.94}, {'start_timestamp': 37.96, 'end_timestamp': 38.34}, {'start_timestamp': 38.42, 'end_timestamp': 38.68}, {'start_timestamp': 39.06, 'end_timestamp': 39.14}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_388/3991066742.py:13: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  data_dict = extracted_data.dict()   # if Pydantic v1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Example: path to your transcription file\n",
    "transcription_path = Path(\"word_level_output.json\")\n",
    "\n",
    "# Load the JSON transcript\n",
    "with open(transcription_path, \"r\") as f:\n",
    "    transcript = json.load(f)\n",
    "\n",
    "# Convert Pydantic model to dict\n",
    "data_dict = extracted_data.dict()   # if Pydantic v1\n",
    "# data_dict = extracted_data.model_dump()  # if Pydantic v2\n",
    "\n",
    "# Collect all searchable words from extracted_data (split multi-word strings)\n",
    "search_terms = set()\n",
    "for v in data_dict.values():\n",
    "    if v and isinstance(v, str):\n",
    "        # Split by spaces\n",
    "        words = v.split()\n",
    "        # Normalize: lowercase, remove punctuation\n",
    "        words = [re.sub(r\"[^\\w]\", \"\", w.lower()) for w in words]\n",
    "        search_terms.update(words)\n",
    "\n",
    "# Extract timestamps of words in transcript matching any search term\n",
    "timestamps = []\n",
    "for entry in transcript:\n",
    "    # Normalize transcript word: lowercase + remove punctuation\n",
    "    normalized_word = re.sub(r\"[^\\w]\", \"\", entry[\"word\"].lower())\n",
    "    if normalized_word in search_terms:\n",
    "        timestamps.append({\n",
    "            \n",
    "            \"start_timestamp\": entry[\"start_timestamp\"],\n",
    "            \"end_timestamp\": entry[\"end_timestamp\"]\n",
    "        })\n",
    "\n",
    "print(timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a46bd824-19c3-44ae-8317-511f061fdfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging beep [10.18-12.20] with [12.24-14.14]\n",
      "Merging beep [36.86-37.66] with [37.72-37.94]\n",
      "Merging beep [36.86-37.94] with [37.96-38.34]\n",
      "Merging beep [36.86-38.34] with [38.42-38.68]\n",
      "Reading WAV file: audio1.wav\n",
      "Audio info: 135.40s, 8000Hz, 1 channels\n",
      "Adding beep 1: 10.18s - 14.14s\n",
      "Adding beep 2: 29.48s - 34.02s\n",
      "Adding beep 3: 36.86s - 38.68s\n",
      "Adding beep 4: 39.06s - 39.14s\n",
      "Writing output file: drive_thru_beep.wav\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import wave\n",
    "import struct\n",
    "from typing import List, Dict\n",
    "\n",
    "def generate_beep(sample_rate: int, duration: float = 0.1, frequency: int = 1000) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate a beep sound as a numpy array.\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    beep = np.sin(2 * np.pi * frequency * t)\n",
    "    fade_samples = int(sample_rate * 0.01)  # 10ms fade\n",
    "    if fade_samples > 0 and len(beep) > fade_samples * 2:\n",
    "        beep[:fade_samples] *= np.linspace(0, 1, fade_samples)\n",
    "        beep[-fade_samples:] *= np.linspace(1, 0, fade_samples)\n",
    "    return beep\n",
    "\n",
    "def read_wav_file(filename: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Read WAV file and return audio data and parameters.\n",
    "    \"\"\"\n",
    "    with wave.open(filename, 'rb') as wav_file:\n",
    "        sample_rate = wav_file.getframerate()\n",
    "        num_channels = wav_file.getnchannels()\n",
    "        sample_width = wav_file.getsampwidth()\n",
    "        num_frames = wav_file.getnframes()\n",
    "        raw_audio = wav_file.readframes(num_frames)\n",
    "        \n",
    "        if sample_width == 1:\n",
    "            dtype = np.uint8\n",
    "            audio_data = np.frombuffer(raw_audio, dtype=dtype)\n",
    "            audio_data = audio_data.astype(np.float32) / 127.5 - 1.0\n",
    "        elif sample_width == 2:\n",
    "            dtype = np.int16\n",
    "            audio_data = np.frombuffer(raw_audio, dtype=dtype)\n",
    "            audio_data = audio_data.astype(np.float32) / 32767.0\n",
    "        elif sample_width == 4:\n",
    "            dtype = np.int32\n",
    "            audio_data = np.frombuffer(raw_audio, dtype=dtype)\n",
    "            audio_data = audio_data.astype(np.float32) / 2147483647.0\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported sample width: {sample_width}\")\n",
    "        \n",
    "        if num_channels > 1:\n",
    "            audio_data = audio_data.reshape(-1, num_channels)\n",
    "    \n",
    "    return audio_data, sample_rate, num_channels, sample_width\n",
    "\n",
    "def write_wav_file(filename: str, audio_data: np.ndarray, sample_rate: int, \n",
    "                   num_channels: int, sample_width: int):\n",
    "    \"\"\"\n",
    "    Write audio data to WAV file.\n",
    "    \"\"\"\n",
    "    if sample_width == 1:\n",
    "        audio_int = ((audio_data + 1.0) * 127.5).astype(np.uint8)\n",
    "    elif sample_width == 2:\n",
    "        audio_int = (audio_data * 32767.0).astype(np.int16)\n",
    "    elif sample_width == 4:\n",
    "        audio_int = (audio_data * 2147483647.0).astype(np.int32)\n",
    "    \n",
    "    with wave.open(filename, 'wb') as wav_file:\n",
    "        wav_file.setnchannels(num_channels)\n",
    "        wav_file.setsampwidth(sample_width)\n",
    "        wav_file.setframerate(sample_rate)\n",
    "        wav_file.writeframes(audio_int.tobytes())\n",
    "\n",
    "def merge_close_timestamps(timestamps: List[Dict], min_gap: float = 0.1) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Merge beeps if the gap between end of one and start of next < min_gap seconds.\n",
    "    \"\"\"\n",
    "    if not timestamps:\n",
    "        return []\n",
    "\n",
    "    merged = [timestamps[0]]\n",
    "    for ts in timestamps[1:]:\n",
    "        last = merged[-1]\n",
    "        if ts[\"start_timestamp\"] - last[\"end_timestamp\"] < min_gap:\n",
    "            print(f\"Merging beep [{last['start_timestamp']:.2f}-{last['end_timestamp']:.2f}] \"\n",
    "                  f\"with [{ts['start_timestamp']:.2f}-{ts['end_timestamp']:.2f}]\")\n",
    "            last[\"end_timestamp\"] = max(last[\"end_timestamp\"], ts[\"end_timestamp\"])\n",
    "        else:\n",
    "            merged.append(ts)\n",
    "    return merged\n",
    "\n",
    "def add_beeps_to_wav(input_file: str, output_file: str, timestamps_json: str, \n",
    "                     beep_volume: float = 0.3, beep_frequency: int = 1000):\n",
    "    \"\"\"\n",
    "    Replace original audio with beeps at specified timestamps.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        timestamps = json.loads(timestamps_json)\n",
    "    except json.JSONDecodeError:\n",
    "        with open(timestamps_json, 'r') as f:\n",
    "            timestamps = json.load(f)\n",
    "\n",
    "    # Merge close timestamps (<100ms apart)\n",
    "    timestamps = merge_close_timestamps(timestamps, min_gap=0.1)\n",
    "\n",
    "    print(f\"Reading WAV file: {input_file}\")\n",
    "    audio_data, sample_rate, num_channels, sample_width = read_wav_file(input_file)\n",
    "\n",
    "    print(f\"Audio info: {len(audio_data)/sample_rate:.2f}s, \"\n",
    "          f\"{sample_rate}Hz, {num_channels} channels\")\n",
    "\n",
    "    audio_duration = len(audio_data) / sample_rate\n",
    "\n",
    "    for i, timestamp in enumerate(timestamps):\n",
    "        start_time = timestamp['start_timestamp']\n",
    "        end_time = timestamp['end_timestamp']\n",
    "\n",
    "        # Clamp inside audio range\n",
    "        start_time = max(0.0, min(start_time, audio_duration))\n",
    "        end_time = max(0.0, min(end_time, audio_duration))\n",
    "\n",
    "        if end_time <= start_time:\n",
    "            print(f\"Skipping beep {i+1}: invalid/zero duration\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Adding beep {i+1}: {start_time:.2f}s - {end_time:.2f}s\")\n",
    "\n",
    "        start_sample = int(start_time * sample_rate)\n",
    "        end_sample = int(end_time * sample_rate)\n",
    "\n",
    "        beep_duration = (end_sample - start_sample) / sample_rate\n",
    "        if beep_duration <= 0:\n",
    "            print(f\"Skipping beep {i+1}: invalid duration {beep_duration}\")\n",
    "            continue\n",
    "\n",
    "        beep = generate_beep(sample_rate, beep_duration, beep_frequency) * beep_volume\n",
    "        beep_length = min(len(beep), end_sample - start_sample)\n",
    "\n",
    "        # First mute the original audio\n",
    "        if num_channels == 1:\n",
    "            audio_data[start_sample:start_sample + beep_length] = 0\n",
    "            audio_data[start_sample:start_sample + beep_length] += beep[:beep_length]\n",
    "        else:\n",
    "            audio_data[start_sample:start_sample + beep_length, :] = 0\n",
    "            for channel in range(num_channels):\n",
    "                audio_data[start_sample:start_sample + beep_length, channel] += beep[:beep_length]\n",
    "\n",
    "    # Normalize if clipping\n",
    "    max_val = np.max(np.abs(audio_data))\n",
    "    if max_val > 1.0:\n",
    "        print(f\"Normalizing audio (max value was {max_val:.3f})\")\n",
    "        audio_data = audio_data / max_val\n",
    "\n",
    "    print(f\"Writing output file: {output_file}\")\n",
    "    write_wav_file(output_file, audio_data, sample_rate, num_channels, sample_width)\n",
    "    print(\"Done!\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the beep inserter.\n",
    "    \"\"\"\n",
    "    input_wav_file = \"audio1.wav\"  \n",
    "    output_wav_file = \"drive_thru_beep.wav\"  \n",
    "\n",
    "    try:\n",
    "        add_beeps_to_wav(\n",
    "            input_file=input_wav_file,\n",
    "            output_file=output_wav_file,\n",
    "            timestamps_json=json.dumps(timestamps),  # pass as JSON string\n",
    "            beep_volume=0.3,\n",
    "            beep_frequency=1000\n",
    "        )\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found - {e}\")\n",
    "        print(\"Please make sure your input audio file exists.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401dc8f9-1345-4508-9063-471db8b2b10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
